{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a92543",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d34d43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Hardware-aware device selection\n",
    "import torch\n",
    "\n",
    "def get_device() -> str:\n",
    "    \"\"\"\n",
    "    Returns the optimal device string for running PyTorch models, prioritizing CUDA (NVIDIA GPUs),\n",
    "    Apple Silicon MPS (Metal), and falling back to CPU. Optionally checks for AMD ROCm/HIP.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    - device: str\n",
    "        Name of the device to use: \"cuda\", \"mps\", \"cpu\", or \"hip\".\n",
    "\n",
    "    Notes\n",
    "    ----------\n",
    "    - On NVIDIA GPUs, \"cuda\" is used for hardware acceleration.\n",
    "    - On Apple Silicon, \"mps\" uses Metal Performance Shaders, providing hardware acceleration.\n",
    "    - On AMD, \"hip\" (ROCm) may be available, but this is uncommon.\n",
    "    - If no GPU is available, it defaults to \"cpu\".\n",
    "    Raises\n",
    "    ----------\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Check for CUDA (NVIDIA GPUs)\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    # or MPS (Apple Silicon)\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    # or ROCm (AMD)\n",
    "    if hasattr(torch.version, \"hip\") and torch.version.hip is not None:\n",
    "        return \"hip\"\n",
    "    # Fallback to CPU\n",
    "    return \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb9c56",
   "metadata": {},
   "source": [
    "# Building the emotionRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560b320",
   "metadata": {},
   "source": [
    "This class loads both transformers, runs inference, and outputs the 35d mood vector for a single input string. Handles device placement and memory cleanup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2457dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "class EmotionRegressor:\n",
    "    \"\"\"\n",
    "    Loads and manages transformer model for emotional analysis, producing a 28-dimensional mood vector for a given text input.\n",
    "    \n",
    "    Models:\n",
    "    ----------\n",
    "    - SamLowe/roberta-base-go_emotions: Predicts confidence scores for 28 discrete emotions (GoEmotions).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - individual_emotion_model_name: str\n",
    "        HuggingFace model name for the 28d emotion regressor (default: \"SamLowe/roberta-base-go_emotions\").\n",
    "        - device: str or None\n",
    "        Device to use for inference (\"cuda\", \"mps\", \"cpu\", etc). If None, selects best available.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    - predict(text: str) -> np.ndarray\n",
    "        Returns a 28d mood vector for a given text.\n",
    "    - cleanup() -> None\n",
    "        Frees model memory for safe re-initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 individual_emotion_model_name: str = \"SamLowe/roberta-base-go_emotions\",\n",
    "                 device: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the EmotionRegressor and load both models on the appropriate device.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        - individual_emotion_model_name: str\n",
    "            Name or path for the 28-emotion model.\n",
    "\n",
    "        - device: str or None\n",
    "            Device for inference.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - None\n",
    "\n",
    "        Raises\n",
    "        -------\n",
    "        - RuntimeError: if model loading fails or device is invalid.\n",
    "        \"\"\"\n",
    "        # Load SamLowe model for individual emotions\n",
    "        self.device = device or get_device()\n",
    "        self.individual_emotion_tokenizer = AutoTokenizer.from_pretrained(individual_emotion_model_name)\n",
    "        self.individual_emotion_model = AutoModelForSequenceClassification.from_pretrained(individual_emotion_model_name).to(self.device)\n",
    "        self.individual_emotion_model.eval()\n",
    "\n",
    "    def predict(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generates a 28-dimensional mood vector for the given input text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        - text: str\n",
    "            The text to analyze for emotion content.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - mood_vector: np.ndarray, shape (28,)\n",
    "            Concatenated vector: [28d GoEmotions scores]\n",
    "\n",
    "        Raises\n",
    "        -------\n",
    "        - ValueError: if the text input is empty or not a string.\n",
    "        - RuntimeError: if inference fails due to hardware or model issues.\n",
    "        \"\"\"\n",
    "        # Validate input\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            raise ValueError(\"Input text must be a non-empty string.\")\n",
    "        \n",
    "        # Lowe model output (28d)\n",
    "        inputs = self.individual_emotion_tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            individual_emotion_logits = self.individual_emotion_model(**inputs).logits\n",
    "            individual_emotion_probs = torch.sigmoid(individual_emotion_logits).cpu().numpy().flatten()  # (28,)\n",
    "            \n",
    "        # Combine into 35d vector\n",
    "        mood_vector = np.concatenate([individual_emotion_probs])\n",
    "        return mood_vector\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"\n",
    "        Releases GPU/CPU memory by deleting model weights.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Delete models to free memory\n",
    "        del self.individual_emotion_model\n",
    "        import gc\n",
    "        # Run garbage collection to free up memory\n",
    "        gc.collect()\n",
    "        # Clear CUDA cache if using GPU\n",
    "        if self.device == \"cuda\":\n",
    "            import torch\n",
    "            torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74268e84",
   "metadata": {},
   "source": [
    "# Demo of 28-dimensional mood_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520cad1",
   "metadata": {},
   "source": [
    "## Hard-coded example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c65ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28d mood_vector: [2.80239899e-03 5.84837422e-03 2.65013836e-02 6.07926965e-01\n",
      " 1.78276524e-02 1.31448160e-03 4.62995330e-03 1.89981493e-03\n",
      " 7.16498680e-03 4.01560247e-01 7.64833987e-02 2.34261509e-02\n",
      " 1.14092352e-02 2.55096215e-03 1.22402806e-03 5.31175407e-04\n",
      " 1.28757767e-03 2.61986558e-03 1.43351580e-03 4.59351484e-03\n",
      " 3.81162507e-03 9.43467370e-04 4.12532315e-02 1.70239829e-03\n",
      " 1.76575605e-03 3.49067971e-02 3.82844801e-03 1.19789466e-01]\n",
      "Shape: (28,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize and demo\n",
    "emotion_regressor = EmotionRegressor(device=device)\n",
    "sample_text = \"ugh. like, im just so OVER everything right now. i have like, three midterms next week and a huge group project that my group members rNT even helping with. i stayed up till 4 am trying to finISH something for it but like, im just SO tired all the time. and my brain feels like mush. üòµ‚Äçüí´ i just cant focus on anythinG. i keep staring at my textbook but the words just blur together.\"\n",
    "mood_vector = emotion_regressor.predict(sample_text)\n",
    "print(\"28d mood_vector:\", mood_vector)\n",
    "print(\"Shape:\", mood_vector.shape)\n",
    "emotion_regressor.cleanup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284bb5f1",
   "metadata": {},
   "source": [
    "## Tinkering with output display format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfc1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                confidence\n",
      "admiration        0.002802\n",
      "amusement         0.005848\n",
      "anger             0.026501\n",
      "annoyance         0.607927\n",
      "approval          0.017828\n",
      "caring            0.001314\n",
      "confusion         0.004630\n",
      "curiosity         0.001900\n",
      "desire            0.007165\n",
      "disappointment    0.401560\n",
      "disapproval       0.076483\n",
      "disgust           0.023426\n",
      "embarrassment     0.011409\n",
      "excitement        0.002551\n",
      "fear              0.001224\n",
      "gratitude         0.000531\n",
      "grief             0.001288\n",
      "joy               0.002620\n",
      "love              0.001434\n",
      "nervousness       0.004594\n",
      "optimism          0.003812\n",
      "pride             0.000943\n",
      "realization       0.041253\n",
      "relief            0.001702\n",
      "remorse           0.001766\n",
      "sadness           0.034907\n",
      "surprise          0.003828\n",
      "neutral           0.119789\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# These should be the order of the GoEmotions and Ekman categories used by your models\n",
    "GOEMOTIONS_LABELS = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
    "    'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness',\n",
    "    'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "\n",
    "def pretty_print_mood_vector(mood_vector):\n",
    "    \"\"\"\n",
    "    Prints the 28d mood vector in a readable format using pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if len(mood_vector) != 28:\n",
    "        raise ValueError(\"Mood vector must be length 28\")\n",
    "    data = {**{f\"{e}\": v for e, v in zip(GOEMOTIONS_LABELS, mood_vector[:28])}}\n",
    "    df = pd.DataFrame([data])\n",
    "    print(df.T.rename(columns={0: 'confidence'}))  # .T to flip to (label, value) per row\n",
    "\n",
    "# Usage\n",
    "pretty_print_mood_vector(mood_vector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bca9fa",
   "metadata": {},
   "source": [
    "# live use (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63038381",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_regressor = EmotionRegressor(device=device)\n",
    "user_input = input(\"Enter text: \")\n",
    "mood_vector = emotion_regressor.predict(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e72c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm a little upset to have to lose the second transformer, it had a much bigger wealth of datasets that it was trained on. but i have to make peace with the fact that its output was too broad, and not very useful for my purposes. hopefully the single-transformer model will be as powerful as the dual-transformer model i've left behind.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010f1a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                confidence\n",
      "admiration        0.006564\n",
      "amusement         0.001623\n",
      "anger             0.004582\n",
      "annoyance         0.064064\n",
      "approval          0.019741\n",
      "caring            0.013333\n",
      "confusion         0.005940\n",
      "curiosity         0.002808\n",
      "desire            0.044165\n",
      "disappointment    0.646095\n",
      "disapproval       0.042262\n",
      "disgust           0.003413\n",
      "embarrassment     0.004060\n",
      "excitement        0.002479\n",
      "fear              0.004360\n",
      "gratitude         0.002509\n",
      "grief             0.004135\n",
      "joy               0.006755\n",
      "love              0.003109\n",
      "nervousness       0.009303\n",
      "optimism          0.471453\n",
      "pride             0.001867\n",
      "realization       0.028679\n",
      "relief            0.005792\n",
      "remorse           0.014383\n",
      "sadness           0.077667\n",
      "surprise          0.003924\n",
      "neutral           0.061537\n"
     ]
    }
   ],
   "source": [
    "pretty_print_mood_vector(mood_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d3af861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00656432 0.0016226  0.00458184 0.0640636  0.01974069 0.01333318\n",
      " 0.0059402  0.00280816 0.04416487 0.6460954  0.04226154 0.00341327\n",
      " 0.00406021 0.00247896 0.00435981 0.00250942 0.00413452 0.00675495\n",
      " 0.00310854 0.00930327 0.47145328 0.00186655 0.02867904 0.00579177\n",
      " 0.01438257 0.07766729 0.0039245  0.06153668]\n"
     ]
    }
   ],
   "source": [
    "print(mood_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af790d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0065643177,\n",
       " 0.0016225978,\n",
       " 0.004581841,\n",
       " 0.0640636,\n",
       " 0.019740686,\n",
       " 0.013333182,\n",
       " 0.005940196,\n",
       " 0.002808163,\n",
       " 0.04416487,\n",
       " 0.6460954,\n",
       " 0.042261545,\n",
       " 0.0034132705,\n",
       " 0.004060205,\n",
       " 0.00247896,\n",
       " 0.0043598125,\n",
       " 0.002509423,\n",
       " 0.00413452,\n",
       " 0.0067549516,\n",
       " 0.0031085385,\n",
       " 0.009303273,\n",
       " 0.47145328,\n",
       " 0.0018665511,\n",
       " 0.028679036,\n",
       " 0.005791767,\n",
       " 0.014382573,\n",
       " 0.07766729,\n",
       " 0.003924499,\n",
       " 0.061536685]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mood_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa17b022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mood_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
