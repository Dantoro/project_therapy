{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a92543",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d34d43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Hardware-aware device selection\n",
    "import torch\n",
    "\n",
    "def get_device() -> str:\n",
    "    \"\"\"\n",
    "    Returns the optimal device string for running PyTorch models, prioritizing CUDA (NVIDIA GPUs),\n",
    "    Apple Silicon MPS (Metal), and falling back to CPU. Optionally checks for AMD ROCm/HIP.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    - device: str\n",
    "        Name of the device to use: \"cuda\", \"mps\", \"cpu\", or \"hip\".\n",
    "\n",
    "    Notes\n",
    "    ----------\n",
    "    - On NVIDIA GPUs, \"cuda\" is used for hardware acceleration.\n",
    "    - On Apple Silicon, \"mps\" uses Metal Performance Shaders, providing hardware acceleration.\n",
    "    - On AMD, \"hip\" (ROCm) may be available, but this is uncommon.\n",
    "    - If no GPU is available, it defaults to \"cpu\".\n",
    "    Raises\n",
    "    ----------\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Check for CUDA (NVIDIA GPUs)\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    # or MPS (Apple Silicon)\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    # or ROCm (AMD)\n",
    "    if hasattr(torch.version, \"hip\") and torch.version.hip is not None:\n",
    "        return \"hip\"\n",
    "    # Fallback to CPU\n",
    "    return \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb9c56",
   "metadata": {},
   "source": [
    "# Building the emotionRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560b320",
   "metadata": {},
   "source": [
    "This class loads both transformers, runs inference, and outputs the 35d mood vector for a single input string. Handles device placement and memory cleanup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2457dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "class EmotionRegressor:\n",
    "    \"\"\"\n",
    "    Loads and manages transformer model for emotional analysis, producing a 28-dimensional mood vector for a given text input.\n",
    "    \n",
    "    Models:\n",
    "    ----------\n",
    "    - SamLowe/roberta-base-go_emotions: Predicts confidence scores for 28 discrete emotions (GoEmotions).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - individual_emotion_model_name: str\n",
    "        HuggingFace model name for the 28d emotion regressor (default: \"SamLowe/roberta-base-go_emotions\").\n",
    "        - device: str or None\n",
    "        Device to use for inference (\"cuda\", \"mps\", \"cpu\", etc). If None, selects best available.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    - predict(text: str) -> np.ndarray\n",
    "        Returns a 28d mood vector for a given text.\n",
    "    - cleanup() -> None\n",
    "        Frees model memory for safe re-initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 individual_emotion_model_name: str = \"SamLowe/roberta-base-go_emotions\",\n",
    "                 device: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the EmotionRegressor and load both models on the appropriate device.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        - individual_emotion_model_name: str\n",
    "            Name or path for the 28-emotion model.\n",
    "\n",
    "        - device: str or None\n",
    "            Device for inference.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - None\n",
    "\n",
    "        Raises\n",
    "        -------\n",
    "        - RuntimeError: if model loading fails or device is invalid.\n",
    "        \"\"\"\n",
    "        # Load SamLowe model for individual emotions\n",
    "        self.device = device or get_device()\n",
    "        self.individual_emotion_tokenizer = AutoTokenizer.from_pretrained(individual_emotion_model_name)\n",
    "        self.individual_emotion_model = AutoModelForSequenceClassification.from_pretrained(individual_emotion_model_name).to(self.device)\n",
    "        self.individual_emotion_model.eval()\n",
    "\n",
    "    def predict(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generates a 28-dimensional mood vector for the given input text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        - text: str\n",
    "            The text to analyze for emotion content.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - mood_vector: np.ndarray, shape (28,)\n",
    "            Concatenated vector: [28d GoEmotions scores]\n",
    "\n",
    "        Raises\n",
    "        -------\n",
    "        - ValueError: if the text input is empty or not a string.\n",
    "        - RuntimeError: if inference fails due to hardware or model issues.\n",
    "        \"\"\"\n",
    "        # Validate input\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            raise ValueError(\"Input text must be a non-empty string.\")\n",
    "        \n",
    "        # Lowe model output (28d)\n",
    "        inputs = self.individual_emotion_tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            individual_emotion_logits = self.individual_emotion_model(**inputs).logits\n",
    "            individual_emotion_probs = torch.sigmoid(individual_emotion_logits).cpu().numpy().flatten()  # (28,)\n",
    "            \n",
    "        # Combine into 35d vector\n",
    "        mood_vector = np.concatenate([individual_emotion_probs])\n",
    "        return mood_vector\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"\n",
    "        Releases GPU/CPU memory by deleting model weights.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Delete models to free memory\n",
    "        del self.individual_emotion_model\n",
    "        import gc\n",
    "        # Run garbage collection to free up memory\n",
    "        gc.collect()\n",
    "        # Clear CUDA cache if using GPU\n",
    "        if self.device == \"cuda\":\n",
    "            import torch\n",
    "            torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74268e84",
   "metadata": {},
   "source": [
    "# Demo of 28-dimensional mood_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520cad1",
   "metadata": {},
   "source": [
    "## Hard-coded example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c65ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28d mood_vector: [2.8023950e-03 5.8483742e-03 2.6501410e-02 6.0792714e-01 1.7827628e-02\n",
      " 1.3144811e-03 4.6299598e-03 1.8998149e-03 7.1649766e-03 4.0156025e-01\n",
      " 7.6483473e-02 2.3426151e-02 1.1409246e-02 2.5509598e-03 1.2240275e-03\n",
      " 5.3117541e-04 1.2875771e-03 2.6198630e-03 1.4335144e-03 4.5935083e-03\n",
      " 3.8116251e-03 9.4346644e-04 4.1253220e-02 1.7023967e-03 1.7657561e-03\n",
      " 3.4906741e-02 3.8284496e-03 1.1978948e-01]\n",
      "Shape: (28,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize and demo\n",
    "emotion_regressor = EmotionRegressor(device=device)\n",
    "sample_text = \"ugh. like, im just so OVER everything right now. i have like, three midterms next week and a huge group project that my group members rNT even helping with. i stayed up till 4 am trying to finISH something for it but like, im just SO tired all the time. and my brain feels like mush. üòµ‚Äçüí´ i just cant focus on anythinG. i keep staring at my textbook but the words just blur together.\"\n",
    "mood_vector = emotion_regressor.predict(sample_text)\n",
    "print(\"28d mood_vector:\", mood_vector)\n",
    "print(\"Shape:\", mood_vector.shape)\n",
    "emotion_regressor.cleanup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284bb5f1",
   "metadata": {},
   "source": [
    "## Tinkering with output display format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83dfc1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                confidence\n",
      "admiration        0.002802\n",
      "amusement         0.005848\n",
      "anger             0.026501\n",
      "annoyance         0.607927\n",
      "approval          0.017828\n",
      "caring            0.001314\n",
      "confusion         0.004630\n",
      "curiosity         0.001900\n",
      "desire            0.007165\n",
      "disappointment    0.401560\n",
      "disapproval       0.076483\n",
      "disgust           0.023426\n",
      "embarrassment     0.011409\n",
      "excitement        0.002551\n",
      "fear              0.001224\n",
      "gratitude         0.000531\n",
      "grief             0.001288\n",
      "joy               0.002620\n",
      "love              0.001434\n",
      "nervousness       0.004594\n",
      "optimism          0.003812\n",
      "pride             0.000943\n",
      "realization       0.041253\n",
      "relief            0.001702\n",
      "remorse           0.001766\n",
      "sadness           0.034907\n",
      "surprise          0.003828\n",
      "neutral           0.119789\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# These should be the order of the GoEmotions and Ekman categories used by your models\n",
    "GOEMOTIONS_LABELS = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
    "    'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness',\n",
    "    'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "\n",
    "def pretty_print_mood_vector(mood_vector):\n",
    "    \"\"\"\n",
    "    Prints the 28d mood vector in a readable format using pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if len(mood_vector) != 28:\n",
    "        raise ValueError(\"Mood vector must be length 28\")\n",
    "    data = {**{f\"{e}\": v for e, v in zip(GOEMOTIONS_LABELS, mood_vector[:28])}}\n",
    "    df = pd.DataFrame([data])\n",
    "    print(df.T.rename(columns={0: 'confidence'}))  # .T to flip to (label, value) per row\n",
    "\n",
    "# Usage\n",
    "pretty_print_mood_vector(mood_vector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63038381",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_regressor = EmotionRegressor(device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bca9fa",
   "metadata": {},
   "source": [
    "# live use (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88517b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input = input(\"Enter text: \")\n",
    "# mood_vector = emotion_regressor.predict(user_input)\n",
    "\n",
    "\n",
    "# print(user_input)\n",
    "# pretty_print_mood_vector(mood_vector)\n",
    "\n",
    "# print(mood_vector)\n",
    "# # list(mood_vector)\n",
    "# len(mood_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879f13e",
   "metadata": {},
   "source": [
    "# Mustafar Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4219e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>disgust</th>\n",
       "      <th>embarrassment</th>\n",
       "      <th>excitement</th>\n",
       "      <th>fear</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>grief</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw your ship. What are you doing out here?</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.167364</td>\n",
       "      <td>0.633605</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.031930</td>\n",
       "      <td>0.292631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What things?</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.140438</td>\n",
       "      <td>0.290607</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.767112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obi-Wan is trying to turn you against me.</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>0.039175</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.941642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Us?</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.007315</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.192334</td>\n",
       "      <td>0.243566</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.763730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love won't save you, Padme. Only my new powers can do that.</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.260631</td>\n",
       "      <td>0.535207</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.026089</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.460228</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.117254</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.128356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I won't lose you the way I lost my mother. I am becoming more powerful than any Jedi has ever dreamed of. And I'm doing it for you. To protect you.</td>\n",
       "      <td>0.165211</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>0.105926</td>\n",
       "      <td>0.799505</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.016019</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.020575</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.104707</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.010219</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.023481</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.061358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Don't you see? We don't HAVE to run away anymore. I have brought PEACE to the Republic. I am more powerful than the Chancellor, I‚ÄîI can overthrow him! And together, you and I can rule the galaxy, make things the way we want them to be!</td>\n",
       "      <td>0.233076</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.486954</td>\n",
       "      <td>0.149432</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.030626</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.031590</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.233981</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.008154</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.085752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don't want to hear any more about Obi-Wan. The Jedi turned against me‚Äîdon't YOU turn against me!</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.336668</td>\n",
       "      <td>0.365505</td>\n",
       "      <td>0.014059</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.341223</td>\n",
       "      <td>0.011912</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.225828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Because of Obi-Wan?</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.331714</td>\n",
       "      <td>0.326455</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.611584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LIAR!</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.018140</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.944372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>You're with HIM! You brought him here to KILL me!</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.194657</td>\n",
       "      <td>0.054170</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.012529</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.684765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                      utterance  \\\n",
       "0                                                                                                                                                                                                 I saw your ship. What are you doing out here?   \n",
       "1                                                                                                                                                                                                                                  What things?   \n",
       "2                                                                                                                                                                                                     Obi-Wan is trying to turn you against me.   \n",
       "3                                                                                                                                                                                                                                           Us?   \n",
       "4                                                                                                                                                                                   Love won't save you, Padme. Only my new powers can do that.   \n",
       "5                                                                                           I won't lose you the way I lost my mother. I am becoming more powerful than any Jedi has ever dreamed of. And I'm doing it for you. To protect you.   \n",
       "6   Don't you see? We don't HAVE to run away anymore. I have brought PEACE to the Republic. I am more powerful than the Chancellor, I‚ÄîI can overthrow him! And together, you and I can rule the galaxy, make things the way we want them to be!   \n",
       "7                                                                                                                                            I don't want to hear any more about Obi-Wan. The Jedi turned against me‚Äîdon't YOU turn against me!   \n",
       "8                                                                                                                                                                                                                           Because of Obi-Wan?   \n",
       "9                                                                                                                                                                                                                                         LIAR!   \n",
       "10                                                                                                                                                                                            You're with HIM! You brought him here to KILL me!   \n",
       "\n",
       "    admiration  amusement     anger  annoyance  approval    caring  confusion  \\\n",
       "0     0.005758   0.001704  0.001566   0.004761  0.011941  0.001409   0.167364   \n",
       "1     0.001477   0.001454  0.002698   0.008272  0.006886  0.000977   0.140438   \n",
       "2     0.001119   0.003742  0.015722   0.039175  0.006835  0.002075   0.001453   \n",
       "3     0.001479   0.001644  0.002167   0.007315  0.008448  0.000899   0.192334   \n",
       "4     0.021315   0.000685  0.003990   0.005125  0.260631  0.535207   0.001789   \n",
       "5     0.165211   0.000572  0.004698   0.008042  0.105926  0.799505   0.001522   \n",
       "6     0.233076   0.000819  0.001495   0.004269  0.486954  0.149432   0.003520   \n",
       "7     0.001119   0.001458  0.336668   0.365505  0.014059  0.005068   0.004058   \n",
       "8     0.001454   0.001482  0.001687   0.007237  0.008366  0.000918   0.331714   \n",
       "9     0.006682   0.003397  0.003256   0.005661  0.018140  0.000999   0.001475   \n",
       "10    0.005771   0.003764  0.194657   0.054170  0.006438  0.002246   0.001342   \n",
       "\n",
       "    curiosity    desire  disappointment  disapproval   disgust  embarrassment  \\\n",
       "0    0.633605  0.001742        0.002052     0.001808  0.001126       0.000838   \n",
       "1    0.290607  0.001064        0.001476     0.002237  0.001187       0.000580   \n",
       "2    0.001190  0.001996        0.003991     0.003704  0.003925       0.001030   \n",
       "3    0.243566  0.000816        0.001354     0.002561  0.001216       0.000657   \n",
       "4    0.002508  0.026089        0.002198     0.009200  0.001145       0.000407   \n",
       "5    0.002435  0.023411        0.006735     0.010634  0.001213       0.000761   \n",
       "6    0.020883  0.038214        0.001884     0.003870  0.000378       0.000259   \n",
       "7    0.002229  0.001700        0.012417     0.341223  0.011912       0.003004   \n",
       "8    0.326455  0.000723        0.001571     0.003576  0.001054       0.000638   \n",
       "9    0.001275  0.000924        0.002234     0.001545  0.003542       0.001161   \n",
       "10   0.001464  0.001290        0.004441     0.003401  0.012529       0.001648   \n",
       "\n",
       "    excitement      fear  gratitude     grief       joy      love  \\\n",
       "0     0.009665  0.002376   0.000845  0.000401  0.001910  0.004675   \n",
       "1     0.002266  0.000871   0.000662  0.000259  0.000835  0.001302   \n",
       "2     0.001299  0.001714   0.000509  0.000368  0.001455  0.000657   \n",
       "3     0.002191  0.000993   0.000703  0.000252  0.000921  0.001332   \n",
       "4     0.004558  0.002016   0.007333  0.001137  0.005327  0.460228   \n",
       "5     0.005350  0.008621   0.016019  0.005381  0.007640  0.020575   \n",
       "6     0.030626  0.001709   0.002263  0.000837  0.031590  0.008447   \n",
       "7     0.001197  0.001565   0.001235  0.000497  0.001463  0.000711   \n",
       "8     0.001336  0.000766   0.000845  0.000242  0.000680  0.001210   \n",
       "9     0.005865  0.002786   0.000998  0.000560  0.003166  0.002484   \n",
       "10    0.003747  0.009035   0.000528  0.001077  0.003454  0.001399   \n",
       "\n",
       "    nervousness  optimism     pride  realization    relief   remorse  \\\n",
       "0      0.001210  0.003146  0.000116     0.010838  0.000296  0.000513   \n",
       "1      0.000350  0.001855  0.000071     0.004315  0.000146  0.000254   \n",
       "2      0.000375  0.003276  0.000299     0.004162  0.000275  0.000324   \n",
       "3      0.000376  0.001850  0.000080     0.005306  0.000158  0.000274   \n",
       "4      0.001299  0.117254  0.001937     0.006563  0.003311  0.002821   \n",
       "5      0.006896  0.104707  0.008777     0.010219  0.011724  0.005370   \n",
       "6      0.001854  0.233981  0.008857     0.011672  0.008154  0.000628   \n",
       "7      0.000616  0.002435  0.000474     0.008487  0.000489  0.000658   \n",
       "8      0.000335  0.002031  0.000062     0.006632  0.000139  0.000352   \n",
       "9      0.000476  0.001399  0.000796     0.006646  0.000506  0.000417   \n",
       "10     0.000812  0.001433  0.000953     0.003026  0.000460  0.000284   \n",
       "\n",
       "     sadness  surprise   neutral  \n",
       "0   0.001328  0.031930  0.292631  \n",
       "1   0.000837  0.006319  0.767112  \n",
       "2   0.002209  0.000864  0.941642  \n",
       "3   0.000803  0.006002  0.763730  \n",
       "4   0.002524  0.000578  0.128356  \n",
       "5   0.023481  0.000978  0.061358  \n",
       "6   0.001606  0.001802  0.085752  \n",
       "7   0.003550  0.001381  0.225828  \n",
       "8   0.000894  0.005571  0.611584  \n",
       "9   0.002013  0.002115  0.944372  \n",
       "10  0.005784  0.002662  0.684765  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Absolute path, since the notebook lives elsewhere\n",
    "ROTS_PATH = \"/Users/dansantoro/Desktop/project_therapy/datasets/rots.csv\"\n",
    "\n",
    "# Load dataset\n",
    "rots_df = pd.read_csv(ROTS_PATH)\n",
    "\n",
    "# Filter Anakin lines, preserve order\n",
    "anakin_df = rots_df[rots_df[\"SPEAKER\"] == \"Anakin\"].reset_index(drop=True)\n",
    "\n",
    "# Collect utterances + emotion vectors\n",
    "rows = []\n",
    "\n",
    "for utterance in anakin_df[\"UTTERANCE\"]:\n",
    "    emotions = emotion_regressor.predict(utterance)\n",
    "    rows.append([utterance] + list(emotions))\n",
    "\n",
    "# Build TrendTracker-style dataframe\n",
    "anakin_trendtracker = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"utterance\",\n",
    "        \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
    "        \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
    "        \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
    "        \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n",
    "        \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(anakin_trendtracker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
