{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a92543",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d34d43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Hardware-aware device selection\n",
    "import torch\n",
    "\n",
    "def get_device() -> str:\n",
    "    \"\"\"\n",
    "    Returns the optimal device string for running PyTorch models, prioritizing CUDA (NVIDIA GPUs),\n",
    "    Apple Silicon MPS (Metal), and falling back to CPU. Optionally checks for AMD ROCm/HIP.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    - device: str\n",
    "        Name of the device to use: \"cuda\", \"mps\", \"cpu\", or \"hip\".\n",
    "\n",
    "    Notes\n",
    "    ----------\n",
    "    - On NVIDIA GPUs, \"cuda\" is used for hardware acceleration.\n",
    "    - On Apple Silicon, \"mps\" uses Metal Performance Shaders, providing hardware acceleration.\n",
    "    - On AMD, \"hip\" (ROCm) may be available, but this is uncommon.\n",
    "    - If no GPU is available, it defaults to \"cpu\".\n",
    "    Raises\n",
    "    ----------\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Check for CUDA (NVIDIA GPUs)\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    # or MPS (Apple Silicon)\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    # or ROCm (AMD)\n",
    "    if hasattr(torch.version, \"hip\") and torch.version.hip is not None:\n",
    "        return \"hip\"\n",
    "    # Fallback to CPU\n",
    "    return \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb9c56",
   "metadata": {},
   "source": [
    "# Building the emotionRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560b320",
   "metadata": {},
   "source": [
    "This class loads both transformers, runs inference, and outputs the 35d mood vector for a single input string. Handles device placement and memory cleanup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2457dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "class EmotionRegressor:\n",
    "    \"\"\"\n",
    "    Loads and manages two transformer models for emotional analysis, producing a 35-dimensional mood vector for a given text input.\n",
    "    \n",
    "    Models:\n",
    "    ----------\n",
    "    - SamLowe/roberta-base-go_emotions: Predicts confidence scores for 28 discrete emotions (GoEmotions).\n",
    "    - j-hartmann/emotion-english-roberta-large: Predicts confidence scores for 7 Ekman emotion categories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - individual_emotion_model_name: str\n",
    "        HuggingFace model name for the 28d emotion regressor (default: \"SamLowe/roberta-base-go_emotions\").\n",
    "    - ekman_category_model_name: str\n",
    "        HuggingFace model name for the 7d Ekman regressor (default: \"j-hartmann/emotion-english-roberta-large\").\n",
    "    - device: str or None\n",
    "        Device to use for inference (\"cuda\", \"mps\", \"cpu\", etc). If None, selects best available.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    - predict(text: str) -> np.ndarray\n",
    "        Returns a 35d mood vector for a given text.\n",
    "    - cleanup() -> None\n",
    "        Frees model memory for safe re-initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 individual_emotion_model_name: str = \"SamLowe/roberta-base-go_emotions\",\n",
    "                 ekman_category_model_name: str = \"j-hartmann/emotion-english-roberta-large\",\n",
    "                 device: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the EmotionRegressor and load both models on the appropriate device.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        - individual_emotion_model_name: str\n",
    "            Name or path for the 28-emotion model.\n",
    "        - ekman_category_model_name: str\n",
    "            Name or path for the 7-Ekman-category model.\n",
    "        - device: str or None\n",
    "            Device for inference.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - None\n",
    "\n",
    "        Raises\n",
    "        -------\n",
    "        - RuntimeError: if model loading fails or device is invalid.\n",
    "        \"\"\"\n",
    "        # Load SamLowe model for individual emotions\n",
    "        self.device = device or get_device()\n",
    "        self.individual_emotion_tokenizer = AutoTokenizer.from_pretrained(individual_emotion_model_name)\n",
    "        self.individual_emotion_model = AutoModelForSequenceClassification.from_pretrained(individual_emotion_model_name).to(self.device)\n",
    "        self.individual_emotion_model.eval()\n",
    "        \n",
    "        # Load hartmann model for Ekman categories\n",
    "        self.ekman_category_tokenizer = AutoTokenizer.from_pretrained(ekman_category_model_name)\n",
    "        self.ekman_category_model = AutoModelForSequenceClassification.from_pretrained(ekman_category_model_name).to(self.device)\n",
    "        self.ekman_category_model.eval()\n",
    "\n",
    "    def predict(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generates a 35-dimensional mood vector for the given input text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        - text: str\n",
    "            The text to analyze for emotion content.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - mood_vector: np.ndarray, shape (35,)\n",
    "            Concatenated vector: [28d GoEmotions scores] + [7d Ekman scores]\n",
    "\n",
    "        Raises\n",
    "        -------\n",
    "        - ValueError: if the text input is empty or not a string.\n",
    "        - RuntimeError: if inference fails due to hardware or model issues.\n",
    "        \"\"\"\n",
    "        # Validate input\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            raise ValueError(\"Input text must be a non-empty string.\")\n",
    "        \n",
    "        # Lowe model output (28d)\n",
    "        inputs = self.individual_emotion_tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            individual_emotion_logits = self.individual_emotion_model(**inputs).logits\n",
    "            individual_emotion_probs = torch.sigmoid(individual_emotion_logits).cpu().numpy().flatten()  # (28,)\n",
    "            \n",
    "        # Hartmann model output (7d)\n",
    "        inputs = self.ekman_category_tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            ekman_category_logits = self.ekman_category_model(**inputs).logits\n",
    "            ekman_category_probs = torch.sigmoid(ekman_category_logits).cpu().numpy().flatten()  # (7,)\n",
    "            \n",
    "        # Combine into 35d vector\n",
    "        mood_vector = np.concatenate([individual_emotion_probs, ekman_category_probs])\n",
    "        return mood_vector\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"\n",
    "        Releases GPU/CPU memory by deleting model weights.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Delete models to free memory\n",
    "        del self.individual_emotion_model, self.ekman_category_model\n",
    "        import gc\n",
    "        # Run garbage collection to free up memory\n",
    "        gc.collect()\n",
    "        # Clear CUDA cache if using GPU\n",
    "        if self.device == \"cuda\":\n",
    "            import torch\n",
    "            torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74268e84",
   "metadata": {},
   "source": [
    "# Demo of 35-dimensional mood_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520cad1",
   "metadata": {},
   "source": [
    "## Hard-coded example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c65ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35d mood_vector: [0.00326003 0.00309266 0.00642972 0.06645703 0.01301786 0.00869487\n",
      " 0.00228629 0.0040405  0.56660604 0.21256632 0.02513171 0.01049309\n",
      " 0.00295363 0.00560902 0.00179183 0.00208721 0.00450544 0.01198611\n",
      " 0.00578792 0.00637366 0.01292751 0.00123158 0.01425911 0.00374253\n",
      " 0.00773546 0.18360841 0.00220226 0.07846184 0.40809634 0.24985953\n",
      " 0.2786624  0.21017288 0.6955236  0.973397   0.29766086]\n",
      "Shape: (35,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize and demo\n",
    "emotion_regressor = EmotionRegressor(device=device)\n",
    "sample_text = \"I'm exhausted and nothing feels worth it. I just want to sleep and not think about school.\"\n",
    "mood_vector = emotion_regressor.predict(sample_text)\n",
    "print(\"35d mood_vector:\", mood_vector)\n",
    "print(\"Shape:\", mood_vector.shape)\n",
    "emotion_regressor.cleanup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c60a54",
   "metadata": {},
   "source": [
    "## Live-user example (doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b098937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     user_input = input(\"Enter text (or 'quit'): \")\n",
    "#     if user_input.lower() == \"quit\":\n",
    "#         break\n",
    "#     mood_vector = emotion_regressor.predict(user_input)\n",
    "#     print(\"35d mood_vector:\", mood_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284bb5f1",
   "metadata": {},
   "source": [
    "## Tinkering with output display format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83dfc1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                confidence\n",
      "admiration        0.003260\n",
      "amusement         0.003093\n",
      "anger             0.006430\n",
      "annoyance         0.066457\n",
      "approval          0.013018\n",
      "caring            0.008695\n",
      "confusion         0.002286\n",
      "curiosity         0.004041\n",
      "desire            0.566606\n",
      "disappointment    0.212566\n",
      "disapproval       0.025132\n",
      "disgust           0.010493\n",
      "embarrassment     0.002954\n",
      "excitement        0.005609\n",
      "fear              0.001792\n",
      "gratitude         0.002087\n",
      "grief             0.004505\n",
      "joy               0.011986\n",
      "love              0.005788\n",
      "nervousness       0.006374\n",
      "optimism          0.012928\n",
      "pride             0.001232\n",
      "realization       0.014259\n",
      "relief            0.003743\n",
      "remorse           0.007735\n",
      "sadness           0.183608\n",
      "surprise          0.002202\n",
      "neutral           0.078462\n",
      "ekman_anger       0.408096\n",
      "ekman_disgust     0.249860\n",
      "ekman_fear        0.278662\n",
      "ekman_joy         0.210173\n",
      "ekman_neutral     0.695524\n",
      "ekman_sadness     0.973397\n",
      "ekman_surprise    0.297661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# These should be the order of the GoEmotions and Ekman categories used by your models\n",
    "GOEMOTIONS_LABELS = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
    "    'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness',\n",
    "    'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "EKMAN_LABELS = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
    "\n",
    "def pretty_print_mood_vector(mood_vector):\n",
    "    \"\"\"\n",
    "    Prints the 35d mood vector in a readable format using pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if len(mood_vector) != 35:\n",
    "        raise ValueError(\"Mood vector must be length 35\")\n",
    "    data = {**{f\"{e}\": v for e, v in zip(GOEMOTIONS_LABELS, mood_vector[:28])},\n",
    "            **{f\"ekman_{e}\": v for e, v in zip(EKMAN_LABELS, mood_vector[28:])}}\n",
    "    df = pd.DataFrame([data])\n",
    "    print(df.T.rename(columns={0: 'confidence'}))  # .T to flip to (label, value) per row\n",
    "\n",
    "# Usage\n",
    "pretty_print_mood_vector(mood_vector)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
