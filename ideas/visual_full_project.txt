                                     ┌──────────────────────────┐
                                     │      User Input          │
                                     └──────────────────────────┘
                                                 │
                                                 ▼
                                  ┌───────────────────────────────┐
                                  │ 1. Emotion Classifier (HAN)   │
                                  │ ┌ Word-level BiLSTM + Attn   │
                                  │ │                             │
                                  │ └ Sentence-level BiLSTM +    │
                                  │   Attn ─┬───────────────────┐│
                                  │          ▼                   ││
                                  │  + Transformer Encoder Block ││
                                  │          │                   ││
                                  │          └──► Outputs:        ││
                                  │              • Emotion label ││
                                  │              • Document vec  ││
                                  └───────────────────────────────┘│
                                                 │                 │
                              ┌──────────────────┴──────────────┐  │
                              │                                 │  │
                              ▼                                 ▼  ▼
        ┌───────────────────────────────┐        ┌───────────────────────────┐
        │2. Short-Term Emotion Memory   │        │3. Long-Term Semantic      │
        │   (rolling buffer of last 10) │        │   Conversation Memory     │
        │ • Implemented via BiGRU over  │        │   (queue of last 20–50    │
        │   softmax-prob vectors        │        │   document embeddings)    │
        └───────────────────────────────┘        └───────────────────────────┘
                              │                                 │
                              └──────────────────┬──────────────┘
                                                 ▼
                                  ┌───────────────────────────────┐
                                  │4. Seq2Seq Decision Maker      │
                                  │  (T5/BART-style)              │
                                  │ • Input: emotion label +      │
                                  │   short-term trend + long-term│
                                  │   context vec                 │
                                  │ • Output: natural-language    │
                                  │   “strategy” prompt:          │
                                  │     – tone guide              │
                                  │     – urgency/inquiry style   │
                                  └───────────────────────────────┘
                                                 │
                                                 ▼
                                  ┌───────────────────────────────┐
                                  │5. Chatbot Engine              │
                                  │  (GPT-style autoregressive)   │
                                  │ • Input: raw text + strategy  │
                                  │   prompt + long-term context  │
                                  │ • Output: actual reply text   │
                                  └───────────────────────────────┘
                                                 │
                                                 ▼
                                     ┌──────────────────────────┐
                                     │      Bot Response        │
                                     └──────────────────────────┘