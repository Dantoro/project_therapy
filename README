# Project Therapy

**A modular, research-driven mental health AI chatbot and analytics pipeline**

---

## Overview

Project Therapy is a next-generation, privacy-conscious AI platform for mental health support, self-tracking, and conversational analytics. It integrates deep natural language understanding with transparent emotional modeling to deliver both therapeutic chat and clinical-grade data insights. The pipeline is engineered for flexibility, explainability, and extensibility, supporting ongoing research and rapid prototyping of new components.

This project is built and maintained by Dan Santoro as a long-term personal and academic research effort, with an explicit focus on:

* Interpretable emotion and intent modeling
* Multi-level context understanding (word, sentence, entry, conversation)
* Blending social media language and clinical dialogue
* High configurability, modularity, and detailed documentation

## Major Components

### 1. Emotion Regressor

A two-model ensemble built on SOTA transformer architectures:

* **GoEmotions Transformer** ([SamLowe/roberta-base-go\_emotions](https://huggingface.co/SamLowe/roberta-base-go_emotions)): Trained on Reddit comments, predicts 28 nuanced emotions with confidence scores for each (multi-label).
* **Ekman Transformer** ([j-hartmann/emotion-english-roberta-large](https://huggingface.co/j-hartmann/emotion-english-roberta-large)): Trained on a blend of 6 academic/research datasets, predicts 6 Ekman basic emotions plus neutral.

The output is a 35d regression vector (28 emotion confidences + 7 Ekman category confidences) per user input. See `ideas/component_specific_ideas/emotion_regressor_logic.md` for details.

### 2. Trend Tracker

A custom temporal analytics module that summarizes the last 10 user entries, calculating:

* First and second derivatives of emotion/ekman vectors (momentum, acceleration)
* Exponential moving averages (EMA)
* Argmax/Top-k emotion/ekman tracking

Produces a 210d vector summarizing current and trend-based emotional state, feeding into the DecisionMaker. See `ideas/component_specific_ideas/trend_tracker_logic.md`.

### 3. Hierarchical Attention Network (HAN)

A deep, multi-level model for full-context conversational analysis, supporting up to 21 STM (Short-Term Memory) entries (10 user-bot pairs + latest user input). Each word in each entry is represented by the concatenation of:

* **GloVe**: 300d (general English semantics)
* **Custom word2vec**: 500d (trained on 4 clinical dialogue datasets; see below)
* **Trainable char-level CNN**: 200d (captures typos, style, emoticons, and non-standard language)

This 1000d vector is projected down to 512d, and then passed through three stacked BiLSTM/attention blocks (word, sentence, entry) and a final output projection to 256d. See `ideas/component_specific_ideas/han_model.md` and `ideas/cnn_model.md`.

### 4. Memory Modules

* **STM (Short-Term Memory)**: Rolling buffer of last N entries (raw text only; CNN is now inside the HAN)
* **LTM (Long-Term Memory)**: Forthcoming; to aggregate and compress distant history for context continuity and advanced analytics

Logic is described in `ideas/component_specific_ideas/memory_module_logic.md`.

### 5. DecisionMaker and Chatbot

A hybrid engine for output generation, leveraging:

* TrendTracker’s 210d vector (emotional calculus over recent inputs)
* HAN’s 256d context vector (deep conversational understanding)
* LTM’s output (size/configuration TBD)

Response selection may be rule-based, retrieval-augmented, or generative, depending on context, safety, and intent.

## Embeddings and Corpus

**Custom word2vec** is a central part of this project, designed to overcome the domain gap of off-the-shelf embeddings. It is trained on sentence-level splits from the following four datasets:

* [AnnoMI](https://www.kaggle.com/datasets/rahulbaburaj/annomi)
* [Depression Detection](https://www.kaggle.com/datasets/ziya07/depression-detection)
* [Mental Health Counseling Conversations](https://www.kaggle.com/datasets/melissamonfared/mental-health-counseling-conversations-k)
* [NLP Mental Health Conversations](https://www.kaggle.com/datasets/thedevastator/nlp-mental-health-conversations/data)

After splitting paired dialogues and further splitting by sentence, the final corpus is expected to exceed 30,000–50,000 samples, maximizing coverage of both patient and clinician speech styles. See `ideas/custom_word2vec_logic.md` for details and corpus processing steps.

## Documentation & Research

Detailed logic and model documentation is available in the `ideas/component_specific_ideas/` folder, with legacy/archived files in `ideas/legacy_ideas/`. Research references and papers used during development are tracked in the `research/` folder.

* [HAN model](ideas/component_specific_ideas/han_model.md)
* [CNN model](ideas/cnn_model.md)
* [Trend Tracker](ideas/component_specific_ideas/trend_tracker_logic.md)
* [Emotion Regressor](ideas/component_specific_ideas/emotion_regressor_logic.md)
* [Word2vec details](ideas/custom_word2vec_logic.md)

For HuggingFace transformer model details, see `research/transformers/emotion_transformers.md`.

## Getting Started

This repo is under rapid development. Minimal working code is in `project_notebooks/`, with Jupyter notebooks for data exploration and prototyping. See `emotionRegressor.ipynb` for emotion/ekman transformer ensemble usage.

## Current Status

* GoEmotions dataset retained for historical analysis, but not used for custom training
* All logic and documentation up to date as of July 2025
* LTM and DecisionMaker/Chatbot in prototyping; main pipelines stable

## Contributing & Contact

No outside contributions at this time. For questions or research collaboration, contact Dan Santoro (`danrsantoro@gmail.com`).

---